<!DOCTYPE html>
<html>
<head>
	<meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
	<meta name="viewport" content="device-width,initial-scale=1.0">
	<meta property="og:image" content="imgs/thumbnail.jpg">
    <title>Hee-Seung Moon</title>
	<link href="style.css" rel="stylesheet" media="all">
	<link href="https://fonts.googleapis.com/css2?family=Merriweather:wght@400;900&display=swap" rel="stylesheet">
	<link href="https://fonts.googleapis.com/css2?family=Open+Sans:wght@400;700&display=swap" rel="stylesheet">
	<link rel="apple-touch-icon" sizes="180x180" href="imgs/favicons/apple-touch-icon.png">
	<link rel="icon" type="image/png" sizes="32x32" href="imgs/favicons/favicon-32x32.png">
	<link rel="icon" type="image/png" sizes="16x16" href="imgs/favicons/favicon-16x16.png">
	<link rel="manifest" href="imgs/favicons/site.webmanifest">
	<link rel="mask-icon" href="imgs/favicons/safari-pinned-tab.svg" color="#5bbad5">
	<meta name="msapplication-TileColor" content="#da532c">
	<meta name="theme-color" content="#ffffff">
</head>

<body>
	<div id="header-bg"></div>
	<ul id="nav">
        <li class="current"><a href="#section-1" id="nav-home" class="home">Hee-Seung Moon</a></li>
        <div class="nav-right">
            <li><a href="#section-2">Researches</a></li>
            <li><a href="#section-3">Publications</a></li>
            <li><a href="#section-4">Awards</a></li>
            <li><a href="cv_hsmoon.pdf" target="_blank" class="filter">CV</a></li>
        </div>
	</ul>

	<div id="container">
		<div class="section-wrapper" id="section-1">
			<div class="section">
				<h1>Hee-Seung Moon</h1>
				<p class="about">
					I am a Ph.D. student at <a href="https://www.yonsei.ac.kr/en_sc/" target="_blank">Yonsei University</a> co-advised by Prof. <a href="https://www.jwseo.com/" target="_blank">Jiwon Seo</a> and <a href="https://esports.yonsei.ac.kr/Prof" target="_blank">Byungjoo Lee</a>.
					I received my bachelor's degree in the <a href="https://sit.yonsei.ac.kr/sit/index.do" target="_blank">School of Integrated Techonology</a> from Yonsei University.
					My research interests lie at the intersection of <strong>human–computer interaction</strong> and <strong>artificial intelligence</strong>.
				</p>
				<p class="contact">
					Contact: hs.moon@yonsei.ac.kr<br>
					<a href="cv_hsmoon.pdf" target="_blank">Curriculum Vitae</a>
					&nbsp;&#8226;&ensp;<a href="https://scholar.google.com/citations?user=nAEPwGAAAAAJ&hl=en" target="_blank">Google Scholar</a>
				</p>
			</div>
		</div>
		
		<div class="section-wrapper" id="section-1">
			<div class="section">
				<h2>News</h2>
				<p class="news-item">
					<span class="date">&#8226; Oct. 2021:</span>
					<span class="contents">Successfully completed the internship. Carried out a project about inverse modeling of RL-based user simulators.</span>
				</p>
				<p class="news-item">
					<span class="date">&#8226; Sep. 2021:</span>
					<span class="contents">1 paper is accepted for publication in IEEE RA-L (<a href="https://ieeexplore.ieee.org/abstract/document/9552483" target="_blank">Page</a>).</span>
				</p>
				<p class="news-item">
					<span class="date">&#8226; Apr. 2021:</span>
					<span class="contents">Started a research internship (6-month) at <a href="https://naver-career.gitbook.io/en/teams/clova-cic" target="_blank">Naver AI Lab</a>.</span>
				</p>
			</div>
		</div>

		<div class="section-wrapper" id="section-2">
			<div class="section">
				<h2>Researches</h2>
				<table>
					<tr class="research-table-row">
						<td class="research-table-img">
							<img class="research-thumbnail" src="imgs/haptic_guidance.jpg"/>
						</td>
						<td class="research-table-txt">
							<p class="research-name">Deep Learning-based Haptic Guidance</p>
							<p class="research-year">2020 – 2021</p>
							<p class="research-caption">
								Haptic guidance (HG) improves users’ task performance through physical interaction between robots and users.
								We presented two types of HG: optimal action-based HG (OAHG), which assists users with an optimal action, user prediction-based HG (UPHG), which assists users with their intended action, and proposed a combined HG approach which utilizes the both HG types.
								Deep learning-based approaches were applied, including self-play-based reinforcement learning for OAHG and meta-learning for UPHG.
								Through a user study, we validated each HG's assisting performance for users conducting a pHRI task and investigated how the user’s subjective evaluation differs for each HG.
							</p>
							<a href="https://dl.acm.org/doi/10.1145/3411764.3445115" target="_blank">Paper</a>
						</td>
					</tr>
					<tr class="research-table-row">
						<td class="research-table-img">
							<img class="research-thumbnail" src="imgs/robotic_guide.jpg"/>
						</td>
						<td class="research-table-txt">
							<p class="research-name">Imaginary Rollout-based Robotic Guide Training</p>
							<p class="research-year">2017 – 2019</p>
							<p class="research-caption">
								Training a robot that engages with humans is challenging, because it is expensive to involve humans in a robot training process requiring numerous data samples. 
								We proposed a deep learning-based model that predict human path following a robot and an evolution strategy-baesd robot training method using "imaginary rollouts" generated by the human predictive model, which compensates for this sample inefficiency problem.
								We applied the proposed method to the training of a robotic guide for visually impaired people, which was designed to collect multimodal human response data and reflect such data when selecting the robot’s actions.
							</p>
							<a href="https://arxiv.org/abs/2008.05054" target="_blank">Paper</a>
						</td>
					</tr>
					<tr class="research-table-row">
						<td class="research-table-img">
							<img class="research-thumbnail" src="imgs/task_recovery.jpg"/>
						</td>
						<td class="research-table-txt">
							<p class="research-name">Study on the Effect of Haptic Information in Human Multitasking</p>
							<p class="research-year">2015 – 2016</p>
							<p class="research-caption">
								We implemented a multimodal task interruption environment involving the simultaneous presentation of visual information and haptic stimuli in order to investigate how the combined stimuli affect the performance on the primary task (i.e., cost of interruption). 
								A user test (n=21) indicated that, within a visuo-tactile task environment, redundant haptic information may not only increase accuracy on the primary task but also reduce the cost of interruption in terms of accuracy.
							</p>
							<a href="https://www.frontiersin.org/articles/10.3389/fpsyg.2016.01924/full" target="_blank">Paper</a>
						</td>
					</tr>
				</table>
			</div>
		</div>

		<div class="section-wrapper" id="section-3">
			<div class="section">
				<h2>Publications</h2>
				<h3>&#8226; Journal and Conference Papers</h3>
				<p class="publication-item">
					<span class="title">Fast User Adaptation for Human Motion Prediction in Physical Human–Robot Interaction</span><br>
					<span class="authors"><strong>H.-S. Moon</strong> and J. Seo</span><br>
					<span class="source">IEEE Robotics and Automation Letters (RA-L)</span>,
					<span class="others">in press</span>
					<a href="https://ieeexplore.ieee.org/abstract/document/9552483" target="_blank">Page</a>
					<a href="https://arxiv.org/abs/2109.08881" target="_blank">arXiv</a>
				</p>
				<p class="publication-item">
					<span class="title">Optimal Action-based or User Prediction-based Haptic Guidance: Can You Do Even Better?</span><br>
					<span class="authors"><strong>H.-S. Moon</strong> and J. Seo</span><br>
					<span class="source">ACM CHI Conference on Human Factors in Computing Systems (CHI)</span>,
					<span class="others">2021</span>
					<a href="https://dl.acm.org/doi/10.1145/3411764.3445115" target="_blank">Page</a>
					<a href="https://arxiv.org/abs/2101.01870" target="_blank">arXiv</a>
				</p>
				<p class="publication-item">
					<span class="title">Prediction of Human Trajectory Following a Haptic Robotic Guide Using Recurrent Neural Networks</span><br>
					<span class="authors"><strong>H.-S. Moon</strong> and J. Seo</span><br>
					<span class="source">IEEE World Haptics Conference (WHC)</span>,
					<span class="others">2019</span>
					<a href="https://ieeexplore.ieee.org/abstract/document/8816157/" target="_blank">Page</a>
					<a href="https://arxiv.org/abs/1903.01027" target="_blank">arXiv</a>
				</p>
				<p class="publication-item">
					<span class="title">Observation of Human Response to a Robotic Guide Using a Variational Autoencoder</span><br>
					<span class="authors"><strong>H.-S. Moon</strong> and J. Seo</span><br>
					<span class="source">IEEE International Conference on Robotic Computing (IRC)</span>,
					<span class="others">2019</span>
					<a href="https://ieeexplore.ieee.org/abstract/document/8675594/" target="_blank">Page</a>
				</p>
				<p class="publication-item">
					<span class="title">Monitoring and Mitigation of Ionospheric Anomalies for GNSS-Based Safety Critical Systems: A review of up-to-date signal processing techniques</span><br>
					<span class="authors">J. Lee, Y. J. Morton, J. Lee, <strong>H.-S. Moon</strong>, and J. Seo</span><br>
					<span class="source">IEEE Signal Processing Magazine</span>,
					<span class="others">vol. 34, no. 5, pp. 96–110, 2017</span>
					<a href="https://ieeexplore.ieee.org/abstract/document/8026593" target="_blank">Page</a>
				</p>
				<p class="publication-item">
					<span class="title">Effect of Redundant Haptic Information on Task Performance During Visuo-Tactile Task Interruption and Recovery</span><br>
					<span class="authors"><strong>H.-S. Moon</strong>, J. Baek, and J. Seo</span><br>
					<span class="source">Frontiers in Psychology</span>,
					<span class="others">vol. 7, art. 1924, 2016</span>
					<a href="https://www.frontiersin.org/articles/10.3389/fpsyg.2016.01924/full" target="_blank">Page</a>
				</p>
				<h3>&#8226; Poster Papers</h3>
				<p class="publication-item">
					<span class="title">Dynamic Difficulty Adjustment via Fast User Adaptation</span><br>
					<span class="authors"><strong>H.-S. Moon</strong> and J. Seo</span><br>
					<span class="source">ACM Symposium on User Interface Software and Technology (UIST) Poster</span>,
					<span class="others">2020</span>
					<a href="https://dl.acm.org/doi/abs/10.1145/3379350.3418578" target="_blank">Page</a>
					<a href="https://arxiv.org/abs/2006.15545" target="_blank">arXiv</a>
				</p>
				<p class="publication-item">
					<span class="title">Adaptive UI from Human Behavior Pattern on Small Screen Interface: Focused on Double-Swipe Interface</span><br>
					<span class="authors"><strong>H.-S. Moon</strong> and D. Y. Ju</span><br>
					<span class="source">International Conference on Human-Computer Interaction (HCI International) Poster</span>,
					<span class="others">2015</span>
					<a href="https://link.springer.com/chapter/10.1007/978-3-319-21383-5_7" target="_blank">Page</a>
				</p>
				<h3>&#8226; Preprint Papers</h3>
				<p class="publication-item">
					<span class="title">Sample-Efficient Training of Robotic Guide Using Human Path Prediction Network</span><br>
					<span class="authors"><strong>H.-S. Moon</strong> and J. Seo</span><br>
					<span class="source">arXiv preprint arXiv:2008.05054</span>,
					<span class="others">2020</span>
					<a href="https://arxiv.org/abs/2008.05054" target="_blank">arXiv</a>
				</p>
			</div>
		</div>
		<div class="section-wrapper" id="section-4">
			<div class="section">
				<h2>Awards & Honors</h2>
				<p class="award-item">
					<span class="name">Graduate fellowship</span>
					<span class="year">&nbsp;&#8226;&ensp;2015 – 2018</span><br>
					<span class="detail">ICT Consilience Creative Program, Ministry of Science and ICT, South Korea</span>
				</p>
				<p class="award-item">
					<span class="name">Best Paper Award</span>
					<span class="year">&nbsp;&#8226;&ensp;2017</span><br>
					<span class="detail">2017 Korea Navigation Institute (KONI) Conference</span>
				</p>
				<p class="award-item">
					<span class="name">Minister's Award from Ministry of Science and ICT, Korea</span>
					<span class="year">&nbsp;&#8226;&ensp;2014</span><br>
					<span class="detail">Creative ICT Convergence Korea 2014</span>
				</p>
				<p class="award-item">
					<span class="name">Undergraduate fellowship</span>
					<span class="year">&nbsp;&#8226;&ensp;2012 – 2014</span><br>
					<span class="detail">ICT Consilience Creative Program, Ministry of Science and ICT, South Korea</span>
				</p>
				<p class="award-item">
					<span class="name">Academic Excellence Award</span>
					<span class="year">&nbsp;&#8226;&ensp;Spring 2014, Fall 2013, Spring 2013</span><br>
					<span class="detail">Yonsei University, Korea</span>
				</p>
			</div>
		</div>
		<div class="bottom">
			<p class="credit">Hee-Seung Moon&nbsp;&nbsp;|&nbsp;&nbsp;hs.moon@yonsei.ac.kr</p>
		</div>
	</div>
	<div id="footer-bg"></div>

	<script src="https://code.jquery.com/jquery-latest.min.js"></script>
	<script src="jquery.nav.js"></script>
	<script>
		$(document).ready(function() {
			$('#nav').onePageNav({
                currentClass: 'current',
                changeHash: false,
                scrollSpeed: 750,
                scrollThreshold: 0.5,
                filter: ':not(.filter)',
                easing: 'swing',
                begin: function() {
                    //I get fired when the animation is starting
                },
                end: function() {
                    //I get fired when the animation is ending
                },
                scrollChange: function($currentListItem) {
                    //I get fired when you enter a section and I pass the list item of the section
                }
            });
		});
	</script>
</body>
</html>